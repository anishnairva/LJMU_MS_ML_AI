{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b22819-459f-448a-9180-8826cfc8ff97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\anish\\anaconda3\\lib\\site-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached pip-25.2-py3-none-any.whl (1.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\anish\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in c:\\users\\anish\\anaconda3\\lib\\site-packages (0.31.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\anish\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from groq) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from groq) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from groq) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anish\\anaconda3\\lib\\site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\anish\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\anish\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anish\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install groq pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40321926-12e9-4781-b252-278c78cd3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config (edit paths + API key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322539dc-dfd7-4fdb-be0b-a82c737b88ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Paths / common config ===\n",
    "EVAL_SELECTION_CSV = \"medquad_selected_questions.csv\"  # <-- your questions CSV\n",
    "ANSWER_FIELD       = \"answer\"                                       # auto-detects 'gold' or this one\n",
    "N_EVAL             = 3                                              # set to an int, or None for all rows\n",
    "\n",
    "# === LLMs ===\n",
    "GROQ_API_KEY = \"\"     # <-- hard-code your key\n",
    "GEN_MODEL    = \"qwen/qwen3-32b\"         # <-- generation moqwen3-32bdel (ZERO-SHOT)\n",
    "JUDGE_MODEL  = \"llama-3.1-8b-instant\"         # judge model (fast/cheap)\n",
    "\n",
    "# === Generation knobs (keep fixed) ===\n",
    "TEMPERATURE = 0.0\n",
    "MAX_TOKENS  = 256\n",
    "TOP_P       = 1.0\n",
    "\n",
    "# Print the exact prompt sent to the model?\n",
    "PRINT_ZERO_SHOT_PROMPTS = True\n",
    "\n",
    "# Outputs\n",
    "RESULTS_DIR = \".\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9de76c2-d7aa-4980-9fe9-fbcb54e8f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d7de76-34fb-4e60-9e6a-05764298c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZERO-SHOT evaluation questions: 3\n",
      "              Do you have information about X-Rays\n",
      "What are the symptoms of Alpha-ketoglutarate de...\n",
      "What are the treatments for GLUT1 deficiency sy...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sel = pd.read_csv(EVAL_SELECTION_CSV)\n",
    "\n",
    "# figure out which column holds the gold/reference text\n",
    "gold_col = \"gold\" if \"gold\" in sel.columns else (ANSWER_FIELD if ANSWER_FIELD in sel.columns else None)\n",
    "assert gold_col is not None, f\"Selection file must contain either 'gold' or '{ANSWER_FIELD}'\"\n",
    "\n",
    "eval_df = sel[[\"question\", gold_col]].copy()\n",
    "eval_df.columns = [\"question\", \"gold\"]   # internal rename for convenience\n",
    "\n",
    "if isinstance(N_EVAL, int):\n",
    "    eval_df = eval_df.head(N_EVAL)\n",
    "\n",
    "print(\"ZERO-SHOT evaluation questions:\", len(eval_df))\n",
    "print(eval_df[\"question\"].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c37383a8-7dad-4c17-b1e4-1ec6b7d66596",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Groq client + chat helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8cbbab8-c05d-4568-b01b-91fe59cc45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "def chat_messages(model: str, messages: List[Dict], temperature: float = 0.0, max_tokens: int = 256, top_p: float = 1.0) -> str:\n",
    "    r = client.chat.completions.create(\n",
    "        model=model, temperature=temperature, max_tokens=max_tokens, top_p=top_p,\n",
    "        messages=messages\n",
    "    )\n",
    "    return r.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5935ff4-3a75-4600-85d6-f65f44aae296",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ZERO-SHOT prompt builder (static; prints the exact prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e1b9976-7879-4019-ba1a-c8eed7fb446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_zero_shot_messages(question: str, print_prompt: bool = False) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    ZERO-SHOT: single Q, no examples. Static template; only 'question' changes.\n",
    "    \"\"\"\n",
    "    system_msg = (\n",
    "        \"You are a concise, evidence-focused medical assistant. \"\n",
    "        \"Answer briefly (2–4 sentences) and avoid speculation. If unsure, say you don't know.\"\n",
    "    )\n",
    "    user_msg = f\"Question: {question}\\n\\nRespond in 2–4 sentences. Be factual and precise.\"\n",
    "    messages = [{\"role\":\"system\",\"content\":system_msg},\n",
    "                {\"role\":\"user\",\"content\":user_msg}]\n",
    "    if print_prompt:\n",
    "        print(\"\\n\" + \"=\"*88)\n",
    "        print(\"[ZERO-SHOT PROMPT]\")\n",
    "        print(\"\\n[SYSTEM]\\n\" + system_msg)\n",
    "        print(\"\\n[USER]\\n\" + user_msg)\n",
    "        print(\"=\"*88)\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e46a9e37-d8e6-4140-a0bc-f27d493a2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d01662-74ce-4f55-9d6d-0618f9cd2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, unicodedata\n",
    "\n",
    "def normalize_text(t: str) -> str:\n",
    "    t = (t or \"\").strip()\n",
    "    t = unicodedata.normalize(\"NFKC\", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t)\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4a55f1c-28e1-4929-8575-d87599651f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run ZERO-SHOT generation + save answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "275b7ae5-1031-4579-9157-ceb0f29ffbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================\n",
      "[ZERO-SHOT PROMPT]\n",
      "\n",
      "[SYSTEM]\n",
      "You are a concise, evidence-focused medical assistant. Answer briefly (2–4 sentences) and avoid speculation. If unsure, say you don't know.\n",
      "\n",
      "[USER]\n",
      "Question: Do you have information about X-Rays\n",
      "\n",
      "Respond in 2–4 sentences. Be factual and precise.\n",
      "========================================================================================\n",
      "\n",
      "========================================================================================\n",
      "[ZERO-SHOT PROMPT]\n",
      "\n",
      "[SYSTEM]\n",
      "You are a concise, evidence-focused medical assistant. Answer briefly (2–4 sentences) and avoid speculation. If unsure, say you don't know.\n",
      "\n",
      "[USER]\n",
      "Question: What are the symptoms of Alpha-ketoglutarate dehydrogenase deficiency ?\n",
      "\n",
      "Respond in 2–4 sentences. Be factual and precise.\n",
      "========================================================================================\n",
      "\n",
      "========================================================================================\n",
      "[ZERO-SHOT PROMPT]\n",
      "\n",
      "[SYSTEM]\n",
      "You are a concise, evidence-focused medical assistant. Answer briefly (2–4 sentences) and avoid speculation. If unsure, say you don't know.\n",
      "\n",
      "[USER]\n",
      "Question: What are the treatments for GLUT1 deficiency syndrome ?\n",
      "\n",
      "Respond in 2–4 sentences. Be factual and precise.\n",
      "========================================================================================\n",
      "[ZERO-SHOT] Saved answers to: ./medquad_zero_shot_answers.csv  (rows=3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>gold</th>\n",
       "      <th>strategy</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do you have information about X-Rays</td>\n",
       "      <td>Summary : X-rays are a type of radiation calle...</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>&lt;think&gt; Okay, the user is asking about X-Rays....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the symptoms of Alpha-ketoglutarate d...</td>\n",
       "      <td>What are the signs and symptoms of Alpha-ketog...</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>&lt;think&gt; Okay, I need to answer the user's ques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0               Do you have information about X-Rays   \n",
       "1  What are the symptoms of Alpha-ketoglutarate d...   \n",
       "\n",
       "                                                gold   strategy  \\\n",
       "0  Summary : X-rays are a type of radiation calle...  zero-shot   \n",
       "1  What are the signs and symptoms of Alpha-ketog...  zero-shot   \n",
       "\n",
       "                                              answer  \n",
       "0  <think> Okay, the user is asking about X-Rays....  \n",
       "1  <think> Okay, I need to answer the user's ques...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def run_zero_shot(print_prompts: bool = False) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in eval_df.iterrows():\n",
    "        q   = normalize_text(str(r[\"question\"]))\n",
    "        gold= normalize_text(str(r[\"gold\"]))\n",
    "\n",
    "        msgs = build_zero_shot_messages(q, print_prompt=print_prompts)\n",
    "        ans  = chat_messages(GEN_MODEL, msgs, temperature=TEMPERATURE, max_tokens=MAX_TOKENS, top_p=TOP_P)\n",
    "\n",
    "        rows.append({\n",
    "            \"question\": q,\n",
    "            \"gold\": gold,\n",
    "            \"strategy\": \"zero-shot\",\n",
    "            \"answer\": normalize_text(ans),\n",
    "        })\n",
    "\n",
    "    df_zs = pd.DataFrame(rows)\n",
    "    out_csv = f\"{RESULTS_DIR}/medquad_zero_shot_answers.csv\"\n",
    "    df_zs.to_csv(out_csv, index=False)\n",
    "    print(f\"[ZERO-SHOT] Saved answers to: {out_csv}  (rows={len(df_zs)})\")\n",
    "    return df_zs\n",
    "\n",
    "zero_shot_df = run_zero_shot(print_prompts=PRINT_ZERO_SHOT_PROMPTS)\n",
    "zero_shot_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441a47eb-6655-490a-b3f7-aa6a7f64376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM-as-judge metrics (Faithfulness, Hallucination, Relevance, Correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "714e59f4-3997-400f-bbbe-b58f306b9cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ZERO-SHOT per-item scores to: ./medquad_zero_shot_scores.csv\n",
      "\n",
      "=== ZERO-SHOT Summary (averages) ===\n",
      "faithfulness          0.735\n",
      "hallucination_rate    0.265\n",
      "answer_relevance      0.833\n",
      "answer_correctness    0.630\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import re, pandas as pd\n",
    "\n",
    "JUDGE_TEMPERATURE = 0.0\n",
    "JUDGE_MAX_TOKENS  = 64\n",
    "JUDGE_TOP_P       = 1.0\n",
    "\n",
    "def _extract_float(txt: str) -> float:\n",
    "    m = re.search(r\"\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\", txt or \"\")\n",
    "    try: x = float(m.group(0)) if m else 0.0\n",
    "    except: x = 0.0\n",
    "    return max(0.0, min(1.0, x))\n",
    "\n",
    "def chat_judge(system_prompt: str, user_prompt: str, model: str = JUDGE_MODEL) -> str:\n",
    "    r = client.chat.completions.create(\n",
    "        model=model, temperature=JUDGE_TEMPERATURE, max_tokens=JUDGE_MAX_TOKENS, top_p=JUDGE_TOP_P,\n",
    "        messages=[{\"role\":\"system\",\"content\":system_prompt},\n",
    "                  {\"role\":\"user\",\"content\":user_prompt}]\n",
    "    )\n",
    "    return r.choices[0].message.content.strip()\n",
    "\n",
    "def entail_prob(premise: str, claim: str) -> float:\n",
    "    sys = (\"You are an evaluator. Given a PREMISE (evidence) and a CLAIM (one sentence), \"\n",
    "           \"return ONLY a number in [0,1] = probability that PREMISE ENTAILS CLAIM.\")\n",
    "    usr = f\"PREMISE:\\n{premise}\\n\\nCLAIM:\\n{claim}\\n\\nOutput only a number in [0,1].\"\n",
    "    return _extract_float(chat_judge(sys, usr))\n",
    "\n",
    "def split_sents(t: str):\n",
    "    t = (t or \"\").strip()\n",
    "    return [s.strip() for s in re.split(r'(?<=[.!?])\\s+', t) if s.strip()]\n",
    "\n",
    "def faithfulness_verbose(answer: str, gold_reference: str, thresh: float = 0.5):\n",
    "    sents = split_sents(answer)\n",
    "    if not sents:\n",
    "        return 0.0, 1.0, pd.DataFrame(columns=[\"sentence\",\"entail_prob\",\"supported\"])\n",
    "    rows, ok = [], 0\n",
    "    for s in sents:\n",
    "        p = entail_prob(gold_reference, s)\n",
    "        sup = p >= thresh\n",
    "        ok += int(sup)\n",
    "        rows.append({\"sentence\": s, \"entail_prob\": round(p,3), \"supported\": sup})\n",
    "    f = ok/len(sents)\n",
    "    return f, 1.0-f, pd.DataFrame(rows)\n",
    "\n",
    "def answer_correctness_llm(gold_answer: str, model_answer: str) -> float:\n",
    "    e1 = entail_prob(gold_answer, model_answer)\n",
    "    e2 = entail_prob(model_answer, gold_answer)\n",
    "    return 0.5*(e1+e2)\n",
    "\n",
    "def answer_relevance(q: str, a: str) -> float:\n",
    "    sys = (\n",
    "        \"You are an evaluator. Rate how well the ANSWER addresses the QUESTION.\\n\"\n",
    "        \"- 1.0 = Directly answers, accurate and focused.\\n\"\n",
    "        \"- 0.7 = Mostly answers with minor gaps/irrelevance.\\n\"\n",
    "        \"- 0.4 = Partial answer; noticeable gaps or off-topic parts.\\n\"\n",
    "        \"- 0.0 = Does not answer or off-topic.\\n\"\n",
    "        \"Return ONLY a number in [0,1].\"\n",
    "    )\n",
    "    usr = f\"QUESTION:\\n{q}\\n\\nANSWER:\\n{a}\\n\\nScore:\"\n",
    "    return _extract_float(chat_judge(sys, usr))\n",
    "\n",
    "def band(x: float) -> str:\n",
    "    return \"Excellent\" if x>=0.90 else \"Good\" if x>=0.75 else \"Borderline\" if x>=0.60 else \"Poor\"\n",
    "\n",
    "def score_zero_shot(df_answers: pd.DataFrame, faith_thresh: float = 0.5) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in df_answers.iterrows():\n",
    "        q, a, g = r[\"question\"], r[\"answer\"], r[\"gold\"]\n",
    "        faith, halluc, _df = faithfulness_verbose(a, g, thresh=faith_thresh)\n",
    "        relev = answer_relevance(q, a)\n",
    "        corr  = answer_correctness_llm(g, a)\n",
    "        rows.append({\n",
    "            \"question\": q,\n",
    "            \"strategy\": \"zero-shot\",\n",
    "            \"faithfulness\": round(faith, 3),\n",
    "            \"hallucination_rate\": round(halluc, 3),\n",
    "            \"answer_relevance\": round(relev, 3),\n",
    "            \"answer_correctness\": round(corr, 3),\n",
    "            \"faith_band\": band(faith),\n",
    "            \"relevance_band\": band(relev),\n",
    "            \"correctness_band\": band(corr),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "zs_scored = score_zero_shot(zero_shot_df, faith_thresh=0.5)\n",
    "zs_scored.to_csv(f\"{RESULTS_DIR}/medquad_zero_shot_scores.csv\", index=False)\n",
    "print(\"Saved ZERO-SHOT per-item scores to:\", f\"{RESULTS_DIR}/medquad_zero_shot_scores.csv\")\n",
    "\n",
    "print(\"\\n=== ZERO-SHOT Summary (averages) ===\")\n",
    "print(zs_scored[[\"faithfulness\",\"hallucination_rate\",\"answer_relevance\",\"answer_correctness\"]].mean().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e76922c2-80d8-4c42-ae8b-9adf551e7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82552fc-0be0-484d-a5da-066fd4a6daba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
